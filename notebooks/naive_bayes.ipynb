{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with naive Bayes classifiers\n",
    "Reference: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#extracting-features-from-text-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144293 entries, 0 to 144292\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   id                  144293 non-null  object \n",
      " 1   discourse_id        144293 non-null  float64\n",
      " 2   discourse_start     144293 non-null  float64\n",
      " 3   discourse_end       144293 non-null  float64\n",
      " 4   discourse_text      144293 non-null  object \n",
      " 5   discourse_type      144293 non-null  object \n",
      " 6   discourse_type_num  144293 non-null  object \n",
      " 7   predictionstring    144293 non-null  object \n",
      "dtypes: float64(3), object(5)\n",
      "memory usage: 8.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# import datasets\n",
    "train_path = \"../data/train.csv\"\n",
    "\n",
    "train_data = pd.read_csv(train_path)\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = train_data['discourse_text']\n",
    "y = train_data['discourse_type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101005, 41751)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer builds a dictionary of features and transforms documents to feature vectors.\n",
    "# CountVectorizer supports counts of N-grams of words or consecutive characters.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2295\n",
      "5610\n"
     ]
    }
   ],
   "source": [
    "# Once fitted, the vectorizer has built a dictionary of feature indices.\n",
    "# The index value of a word in the vocabulary is linked to its frequency in the whole training corpus.\n",
    "\n",
    "print(count_vect.vocabulary_.get(u'and'))\n",
    "print(count_vect.vocabulary_.get(u'but'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101005, 41751)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalisation step: from occurrences to frequencies\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and train multinomial classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:   Students should not be allowed to design their summer projects \n",
      "predicted category:  Claim\n",
      "real category:  Position\n",
      "text:  Finally, The FACS could help find if students are depressed or having problems at home.\n",
      "predicted category:  Claim\n",
      "real category:  Claim\n",
      "text:  You might say that not all sports are right after school, and I'd say that is correct,\n",
      "predicted category:  Evidence\n",
      "real category:  Counterclaim\n",
      "text:  Every student should do at least 2 community services. Maybe one at home and one at school\n",
      "predicted category:  Claim\n",
      "real category:  Evidence\n",
      "text:  Social Skills are a key component of learning through any type of school. The interaction between other students is extremely valuable because it builds relationships and confidence. \n",
      "predicted category:  Claim\n",
      "real category:  Claim\n",
      "text:  Where as if I'm at home I can be free complete things on my time, I can take time on my assignments, I don't have to compare myself to others, and I can be me. At home there is no one to judge and I feel more comfortable to work at home.\n",
      "predicted category:  Evidence\n",
      "real category:  Rebuttal\n",
      "text:  They have to improve their grades to get what they want. And if they don't want to, then they shouldn't be allowed in sports. \n",
      "predicted category:  Claim\n",
      "real category:  Rebuttal\n",
      "text:  Also, due to the fact that the Electoral College mainly operates with the winner-take-all rule, it is easy for individuals in Democratic or Republican states to feel as if their vote doesn't matter. \n",
      "predicted category:  Evidence\n",
      "real category:  Claim\n",
      "text:  Secondly, with the technology we have today our team would've definitely knew something was up the first time we saw it \n",
      "predicted category:  Claim\n",
      "real category:  Claim\n",
      "text:  I believe that if you are too lazy to drive somewhere then you shouldn't be driving.\n",
      "predicted category:  Claim\n",
      "real category:  Claim\n"
     ]
    }
   ],
   "source": [
    "X_test_counts = count_vect.transform(X_test)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "predicted = clf.predict(X_test_tfidf)\n",
    "\n",
    "for i in range(10):\n",
    "  print('text: ', X_test.iloc[i])\n",
    "  print('predicted category: ', predicted[i])\n",
    "  print('real category: ', y_test.iloc[i])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same thing with pipeline\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# text_clf = Pipeline([\n",
    "#   ('vect', CountVectorizer()),\n",
    "#   ('tfidf', TfidfTransformer()),\n",
    "#   ('clf', MultinomialNB()),\n",
    "# ])\n",
    "# text_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.4969275549805951\n"
     ]
    }
   ],
   "source": [
    "# evaluate performance\n",
    "import numpy as np\n",
    "accuracy = np.mean(predicted == y_test)\n",
    "print('accuracy: ', accuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better than random! \n",
    "\n",
    "7 categories -> approximately 14.2% to randomly get it right. \n",
    "\n",
    "It's a start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportions of discourse types in the whole dataset:\n",
      "Claim                   50208\n",
      "Evidence                45702\n",
      "Position                15419\n",
      "Concluding Statement    13505\n",
      "Lead                     9305\n",
      "Counterclaim             5817\n",
      "Rebuttal                 4337\n",
      "Name: discourse_type, dtype: int64\n",
      "proportions of discourse types in the train dataset:\n",
      "Claim                   35266\n",
      "Evidence                32073\n",
      "Position                10792\n",
      "Concluding Statement     9352\n",
      "Lead                     6513\n",
      "Counterclaim             4060\n",
      "Rebuttal                 2949\n",
      "Name: discourse_type, dtype: int64\n",
      "proportions of discourse types in the test dataset:\n",
      "Claim                   14942\n",
      "Evidence                13629\n",
      "Position                 4627\n",
      "Concluding Statement     4153\n",
      "Lead                     2792\n",
      "Counterclaim             1757\n",
      "Rebuttal                 1388\n",
      "Name: discourse_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "discourse_types = list(set(train_data[\"discourse_type\"]))\n",
    "print('proportions of discourse types in the whole dataset:')\n",
    "print(train_data[\"discourse_type\"].value_counts())\n",
    "print('proportions of discourse types in the train dataset:')\n",
    "print(y_train.value_counts())\n",
    "print('proportions of discourse types in the test dataset:')\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for y_test predictions\n",
      "[[10074     2     0  4849     0    17     0]\n",
      " [ 2667    19     0  1427     0    40     0]\n",
      " [ 1033     1     7   706     0    10     0]\n",
      " [ 2975     1     0 10652     0     1     0]\n",
      " [ 1246     2     0  1480     9    55     0]\n",
      " [ 3144     4     0   729     0   750     0]\n",
      " [  600     1     0   781     0     6     0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('confusion matrix for y_test predictions')\n",
    "print(metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somehow the normalization steps (?) killed our most uncommon categories!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.5891933099242285\n"
     ]
    }
   ],
   "source": [
    "# Linear support vector machine classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([\n",
    "  ('vect', CountVectorizer()),\n",
    "  ('tfidf', TfidfTransformer()),\n",
    "  ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                        alpha=1e-3, random_state=42,\n",
    "                        max_iter=5, tol=None)),\n",
    "])\n",
    "text_clf.fit(X_train, y_train)\n",
    "predicted2 = text_clf.predict(X_test)\n",
    "accuracy2 = np.mean(predicted2 == y_test)\n",
    "print('accuracy: ', accuracy2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear support vector machine improves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter fine tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "  'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "  'tfidf__use_idf': (True, False),\n",
    "  'clf__alpha': (1e-2, 1e-3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_jobs = -1 automatically detects the number of CPUs and uses all of them\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__alpha: 0.001\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "gs_clf.best_score_\n",
    "for param_name in sorted(parameters.keys()):\n",
    "  print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__alpha</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>param_vect__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.562967</td>\n",
       "      <td>0.204772</td>\n",
       "      <td>0.642171</td>\n",
       "      <td>0.062093</td>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__alpha': 0.01, 'tfidf__use_idf': True, '...</td>\n",
       "      <td>0.573833</td>\n",
       "      <td>0.569328</td>\n",
       "      <td>0.570516</td>\n",
       "      <td>0.565665</td>\n",
       "      <td>0.565814</td>\n",
       "      <td>0.569031</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.735479</td>\n",
       "      <td>1.435859</td>\n",
       "      <td>2.098346</td>\n",
       "      <td>0.092145</td>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__alpha': 0.01, 'tfidf__use_idf': True, '...</td>\n",
       "      <td>0.608485</td>\n",
       "      <td>0.602247</td>\n",
       "      <td>0.605515</td>\n",
       "      <td>0.607049</td>\n",
       "      <td>0.601703</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.158236</td>\n",
       "      <td>0.578517</td>\n",
       "      <td>0.681346</td>\n",
       "      <td>0.057018</td>\n",
       "      <td>0.01</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__alpha': 0.01, 'tfidf__use_idf': False, ...</td>\n",
       "      <td>0.561705</td>\n",
       "      <td>0.557646</td>\n",
       "      <td>0.562348</td>\n",
       "      <td>0.557052</td>\n",
       "      <td>0.558685</td>\n",
       "      <td>0.559487</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.946556</td>\n",
       "      <td>0.549225</td>\n",
       "      <td>1.895764</td>\n",
       "      <td>0.098344</td>\n",
       "      <td>0.01</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__alpha': 0.01, 'tfidf__use_idf': False, ...</td>\n",
       "      <td>0.563190</td>\n",
       "      <td>0.558784</td>\n",
       "      <td>0.561358</td>\n",
       "      <td>0.560022</td>\n",
       "      <td>0.560566</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.989622</td>\n",
       "      <td>0.541587</td>\n",
       "      <td>0.730322</td>\n",
       "      <td>0.127181</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__alpha': 0.001, 'tfidf__use_idf': True, ...</td>\n",
       "      <td>0.594278</td>\n",
       "      <td>0.591604</td>\n",
       "      <td>0.592842</td>\n",
       "      <td>0.595713</td>\n",
       "      <td>0.595119</td>\n",
       "      <td>0.593911</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.666392</td>\n",
       "      <td>0.471575</td>\n",
       "      <td>2.140420</td>\n",
       "      <td>0.210836</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__alpha': 0.001, 'tfidf__use_idf': True, ...</td>\n",
       "      <td>0.612742</td>\n",
       "      <td>0.604228</td>\n",
       "      <td>0.607643</td>\n",
       "      <td>0.609475</td>\n",
       "      <td>0.604772</td>\n",
       "      <td>0.607772</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.951309</td>\n",
       "      <td>0.544204</td>\n",
       "      <td>0.695628</td>\n",
       "      <td>0.132648</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__alpha': 0.001, 'tfidf__use_idf': False,...</td>\n",
       "      <td>0.587100</td>\n",
       "      <td>0.580565</td>\n",
       "      <td>0.584278</td>\n",
       "      <td>0.586060</td>\n",
       "      <td>0.585021</td>\n",
       "      <td>0.584605</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.603353</td>\n",
       "      <td>0.605008</td>\n",
       "      <td>1.511245</td>\n",
       "      <td>0.150702</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__alpha': 0.001, 'tfidf__use_idf': False,...</td>\n",
       "      <td>0.592297</td>\n",
       "      <td>0.586308</td>\n",
       "      <td>0.588486</td>\n",
       "      <td>0.591951</td>\n",
       "      <td>0.588733</td>\n",
       "      <td>0.589555</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       4.562967      0.204772         0.642171        0.062093   \n",
       "1      17.735479      1.435859         2.098346        0.092145   \n",
       "2       5.158236      0.578517         0.681346        0.057018   \n",
       "3      16.946556      0.549225         1.895764        0.098344   \n",
       "4       4.989622      0.541587         0.730322        0.127181   \n",
       "5      18.666392      0.471575         2.140420        0.210836   \n",
       "6       4.951309      0.544204         0.695628        0.132648   \n",
       "7      14.603353      0.605008         1.511245        0.150702   \n",
       "\n",
       "  param_clf__alpha param_tfidf__use_idf param_vect__ngram_range  \\\n",
       "0             0.01                 True                  (1, 1)   \n",
       "1             0.01                 True                  (1, 2)   \n",
       "2             0.01                False                  (1, 1)   \n",
       "3             0.01                False                  (1, 2)   \n",
       "4            0.001                 True                  (1, 1)   \n",
       "5            0.001                 True                  (1, 2)   \n",
       "6            0.001                False                  (1, 1)   \n",
       "7            0.001                False                  (1, 2)   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'clf__alpha': 0.01, 'tfidf__use_idf': True, '...           0.573833   \n",
       "1  {'clf__alpha': 0.01, 'tfidf__use_idf': True, '...           0.608485   \n",
       "2  {'clf__alpha': 0.01, 'tfidf__use_idf': False, ...           0.561705   \n",
       "3  {'clf__alpha': 0.01, 'tfidf__use_idf': False, ...           0.563190   \n",
       "4  {'clf__alpha': 0.001, 'tfidf__use_idf': True, ...           0.594278   \n",
       "5  {'clf__alpha': 0.001, 'tfidf__use_idf': True, ...           0.612742   \n",
       "6  {'clf__alpha': 0.001, 'tfidf__use_idf': False,...           0.587100   \n",
       "7  {'clf__alpha': 0.001, 'tfidf__use_idf': False,...           0.592297   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.569328           0.570516           0.565665           0.565814   \n",
       "1           0.602247           0.605515           0.607049           0.601703   \n",
       "2           0.557646           0.562348           0.557052           0.558685   \n",
       "3           0.558784           0.561358           0.560022           0.560566   \n",
       "4           0.591604           0.592842           0.595713           0.595119   \n",
       "5           0.604228           0.607643           0.609475           0.604772   \n",
       "6           0.580565           0.584278           0.586060           0.585021   \n",
       "7           0.586308           0.588486           0.591951           0.588733   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.569031        0.003067                6  \n",
       "1         0.605000        0.002648                2  \n",
       "2         0.559487        0.002148                8  \n",
       "3         0.560784        0.001466                7  \n",
       "4         0.593911        0.001504                3  \n",
       "5         0.607772        0.003136                1  \n",
       "6         0.584605        0.002233                5  \n",
       "7         0.589555        0.002264                4  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(gs_clf.cv_results_)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
